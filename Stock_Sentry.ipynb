{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8jcEKv6CfFu",
        "outputId": "9db501a9-abdb-425f-9a11-f134565cf6b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to StockSentry\n",
            "==============================\n",
            "🔐 Could not access Colab secrets. Using demo mode.\n",
            "Enter stock ticker (e.g., AAPL, GOOGL, TSLA): AAPL\n",
            "\n",
            "Enter date range for training data:\n",
            "Start date (YYYY-MM-DD format, e.g., 2023-01-01): 2023-05-01\n",
            "End date (YYYY-MM-DD format, e.g., 2023-06-30): 2025-01-01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "🔄 Training models for AAPL...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Best model: Lasso (R² = 0.9920)\n",
            "📊 Current price: $249.82\n",
            "🤖 Predicted price: $249.80\n",
            "📉 Expected change: $-0.02 (-0.01%)\n",
            "\n",
            "🎯 Final Prediction: $249.80\n",
            "\n",
            "==============================\n",
            "✅ Analysis complete!\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from google.colab import userdata\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class StockSentryML:\n",
        "    \"\"\"Enhanced StockSentry with multiple ML models and proper validation\"\"\"\n",
        "\n",
        "    def __init__(self, news_api_key):\n",
        "        self.news_api_key = news_api_key\n",
        "        self.models = {}\n",
        "        self.best_model = None\n",
        "        self.data = None\n",
        "\n",
        "    def get_news_sentiment(self, company, date):\n",
        "        \"\"\"Get news sentiment with proper error handling\"\"\"\n",
        "        if not self.news_api_key or self.news_api_key == \"your_api_key_here\":\n",
        "            # Return random sentiment between -0.1 and 0.1 for demo purposes\n",
        "            return np.random.uniform(-0.1, 0.1)\n",
        "\n",
        "        url = ('https://newsapi.org/v2/everything?'\n",
        "               f'q={company}&from={date}&to={date}&sortBy=relevance&language=en&apiKey={self.news_api_key}')\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10).json()\n",
        "            sentiments = []\n",
        "            for article in response.get('articles', []):\n",
        "                if article.get('title'):\n",
        "                    headline = article['title']\n",
        "                    sentiment = TextBlob(headline).sentiment.polarity  # -1 to +1\n",
        "                    sentiments.append(sentiment)\n",
        "\n",
        "            if sentiments:\n",
        "                avg_sentiment = sum(sentiments) / len(sentiments)\n",
        "                return float(avg_sentiment)  # Ensure it's a single float\n",
        "            else:\n",
        "                return 0.0\n",
        "        except Exception as e:\n",
        "            return 0.0\n",
        "\n",
        "    def fetch_stock_data(self, ticker, start_date=\"2023-01-01\", end_date=\"2023-06-30\"):\n",
        "        \"\"\"Fetch stock data with proper error handling\"\"\"\n",
        "        try:\n",
        "            self.data = yf.download(ticker, start=start_date, end=end_date)\n",
        "            if self.data.empty:\n",
        "                raise ValueError(f\"No data found for ticker {ticker}\")\n",
        "\n",
        "            self.data.reset_index(inplace=True)\n",
        "            return self.data\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error fetching data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def prepare_features(self, ticker):\n",
        "        \"\"\"Prepare features with fixed indexing\"\"\"\n",
        "        if self.data is None:\n",
        "            raise ValueError(\"No data available. Call fetch_stock_data first.\")\n",
        "\n",
        "        features = []\n",
        "        targets = []\n",
        "\n",
        "        for i in range(len(self.data) - 1):\n",
        "            try:\n",
        "                # Fixed indexing - access scalar values directly\n",
        "                current_date = self.data.loc[i, 'Date']\n",
        "                if hasattr(current_date, 'strftime'):\n",
        "                    date_str = current_date.strftime('%Y-%m-%d')\n",
        "                else:\n",
        "                    date_str = str(current_date)[:10]  # Take first 10 chars (YYYY-MM-DD)\n",
        "\n",
        "                # Get sentiment\n",
        "                sentiment = self.get_news_sentiment(ticker, date_str)\n",
        "\n",
        "                # Ensure sentiment is a single float\n",
        "                if isinstance(sentiment, (list, tuple, np.ndarray)):\n",
        "                    sentiment = float(sentiment[0]) if len(sentiment) > 0 else 0.0\n",
        "                else:\n",
        "                    sentiment = float(sentiment)\n",
        "\n",
        "                # Get prices - handle both Series and scalar values\n",
        "                current_close = self.data.loc[i, 'Close']\n",
        "                next_close = self.data.loc[i + 1, 'Close']\n",
        "\n",
        "                # Convert to float if needed\n",
        "                if hasattr(current_close, 'iloc'):\n",
        "                    current_close = float(current_close.iloc[0])\n",
        "                else:\n",
        "                    current_close = float(current_close)\n",
        "\n",
        "                if hasattr(next_close, 'iloc'):\n",
        "                    next_close = float(next_close.iloc[0])\n",
        "                else:\n",
        "                    next_close = float(next_close)\n",
        "\n",
        "                # Create feature vector\n",
        "                feature_vector = [current_close, sentiment]\n",
        "                features.append(feature_vector)\n",
        "                targets.append(next_close)\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        return np.array(features), np.array(targets)\n",
        "\n",
        "    def initialize_models(self):\n",
        "        \"\"\"Initialize multiple ML models\"\"\"\n",
        "        self.models = {\n",
        "            'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "            'Ridge': Ridge(alpha=1.0, random_state=42),\n",
        "            'Lasso': Lasso(alpha=1.0, random_state=42, max_iter=2000),\n",
        "            'SVR': SVR(kernel='rbf', C=1.0)\n",
        "        }\n",
        "\n",
        "        # Only include XGBoost if available\n",
        "        try:\n",
        "            import xgboost as xgb\n",
        "            self.models['XGBoost'] = xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0)\n",
        "        except ImportError:\n",
        "            pass\n",
        "\n",
        "    def evaluate_model(self, model, X_train, X_test, y_train, y_test):\n",
        "        \"\"\"Comprehensive model evaluation\"\"\"\n",
        "        try:\n",
        "            # Train model\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predictions\n",
        "            train_pred = model.predict(X_train)\n",
        "            test_pred = model.predict(X_test)\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = {\n",
        "                'train_r2': r2_score(y_train, train_pred),\n",
        "                'test_r2': r2_score(y_test, test_pred),\n",
        "                'train_mae': mean_absolute_error(y_train, train_pred),\n",
        "                'test_mae': mean_absolute_error(y_test, test_pred),\n",
        "                'train_rmse': np.sqrt(mean_squared_error(y_train, train_pred)),\n",
        "                'test_rmse': np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "            }\n",
        "\n",
        "            # Directional accuracy (financial metric)\n",
        "            if len(y_test) > 1:\n",
        "                actual_direction = np.sign(np.diff(y_test))\n",
        "                pred_direction = np.sign(np.diff(test_pred))\n",
        "                directional_accuracy = np.mean(actual_direction == pred_direction)\n",
        "                metrics['directional_accuracy'] = directional_accuracy\n",
        "            else:\n",
        "                metrics['directional_accuracy'] = 0.0\n",
        "\n",
        "            return metrics, test_pred\n",
        "        except Exception as e:\n",
        "            return None, None\n",
        "\n",
        "    def train_with_cross_validation(self, X, y):\n",
        "        \"\"\"Train models with time-series cross-validation\"\"\"\n",
        "        tscv = TimeSeriesSplit(n_splits=3)\n",
        "        results = {}\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            try:\n",
        "                cv_scores = []\n",
        "                for train_idx, val_idx in tscv.split(X):\n",
        "                    X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
        "                    y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
        "\n",
        "                    model.fit(X_train_cv, y_train_cv)\n",
        "                    val_pred = model.predict(X_val_cv)\n",
        "                    cv_score = r2_score(y_val_cv, val_pred)\n",
        "                    cv_scores.append(cv_score)\n",
        "\n",
        "                results[name] = {\n",
        "                    'cv_mean': np.mean(cv_scores),\n",
        "                    'cv_std': np.std(cv_scores),\n",
        "                    'model': model\n",
        "                }\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        return results\n",
        "\n",
        "    def hyperparameter_tuning(self, X, y):\n",
        "        \"\"\"Tune hyperparameters for best models\"\"\"\n",
        "        param_grids = {\n",
        "            'RandomForest': {\n",
        "                'n_estimators': [50, 100],\n",
        "                'max_depth': [10, 20, None],\n",
        "                'min_samples_split': [2, 5]\n",
        "            },\n",
        "            'Ridge': {\n",
        "                'alpha': [0.1, 1.0, 10.0]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Add XGBoost params if available\n",
        "        if 'XGBoost' in self.models:\n",
        "            param_grids['XGBoost'] = {\n",
        "                'n_estimators': [50, 100],\n",
        "                'learning_rate': [0.1, 0.2],\n",
        "                'max_depth': [3, 4]\n",
        "            }\n",
        "\n",
        "        tuned_models = {}\n",
        "        tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "        for name in param_grids.keys():\n",
        "            if name in self.models:\n",
        "                try:\n",
        "                    base_model = self.models[name]\n",
        "                    grid_search = GridSearchCV(\n",
        "                        base_model,\n",
        "                        param_grids[name],\n",
        "                        cv=tscv,\n",
        "                        scoring='r2',\n",
        "                        n_jobs=-1,\n",
        "                        verbose=0\n",
        "                    )\n",
        "\n",
        "                    grid_search.fit(X, y)\n",
        "                    tuned_models[name] = grid_search.best_estimator_\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "        return tuned_models\n",
        "\n",
        "    def create_ensemble(self, models):\n",
        "        \"\"\"Create ensemble model\"\"\"\n",
        "        if len(models) < 2:\n",
        "            return list(models.values())[0] if models else None\n",
        "\n",
        "        estimators = [(name, model) for name, model in models.items()]\n",
        "        ensemble = VotingRegressor(estimators=estimators)\n",
        "        return ensemble\n",
        "\n",
        "    def train_and_evaluate(self, ticker, start_date=\"2023-01-01\", end_date=\"2023-06-30\"):\n",
        "        \"\"\"Complete training and evaluation pipeline\"\"\"\n",
        "        print(f\"🔄 Training models for {ticker}...\")\n",
        "\n",
        "        try:\n",
        "            # Fetching the  data and preparing  features\n",
        "            self.fetch_stock_data(ticker, start_date, end_date)\n",
        "            X, y = self.prepare_features(ticker)\n",
        "\n",
        "            if len(X) == 0:\n",
        "                raise ValueError(\"No features prepared\")\n",
        "\n",
        "            # 2. Initialize and train models\n",
        "            self.initialize_models()\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # 3. Train models with cross-validation (silent)\n",
        "            cv_results = self.train_with_cross_validation(X, y)\n",
        "\n",
        "            # 4. Hyperparameter tuning (silent)\n",
        "            tuned_models = self.hyperparameter_tuning(X, y)\n",
        "\n",
        "            # 5. Evaluate all models and select best (silent)\n",
        "            all_models = {**self.models, **tuned_models}\n",
        "            best_r2 = -np.inf\n",
        "            best_model_name = None\n",
        "\n",
        "            for name, model in all_models.items():\n",
        "                metrics, predictions = self.evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "                if metrics and metrics['test_r2'] > best_r2:\n",
        "                    best_r2 = metrics['test_r2']\n",
        "                    self.best_model = model\n",
        "                    best_model_name = name\n",
        "\n",
        "            # 6. Try ensemble as backup\n",
        "            if tuned_models:\n",
        "                ensemble = self.create_ensemble(tuned_models)\n",
        "                if ensemble:\n",
        "                    ensemble_metrics, _ = self.evaluate_model(ensemble, X_train, X_test, y_train, y_test)\n",
        "                    if ensemble_metrics and ensemble_metrics['test_r2'] > best_r2:\n",
        "                        best_r2 = ensemble_metrics['test_r2']\n",
        "                        self.best_model = ensemble\n",
        "                        best_model_name = \"Ensemble\"\n",
        "\n",
        "            print(f\"✅ Best model: {best_model_name} (R² = {best_r2:.4f})\")\n",
        "\n",
        "            return self.best_model\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  Training failed, using fallback model\")\n",
        "            # Fallback to simple Simple model\n",
        "            self.best_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "            self.best_model.fit(X_train, y_train)\n",
        "            return self.best_model\n",
        "\n",
        "    def predict_next_day(self, ticker):\n",
        "        \"\"\"Predict next day price using the best model\"\"\"\n",
        "        if self.data is None or self.best_model is None:\n",
        "            raise ValueError(\"Train the model first using train_and_evaluate()\")\n",
        "\n",
        "        try:\n",
        "            # Get latest data\n",
        "            latest_idx = len(self.data) - 1\n",
        "            latest_date = self.data.loc[latest_idx, 'Date']\n",
        "\n",
        "            if hasattr(latest_date, 'strftime'):\n",
        "                date_str = latest_date.strftime('%Y-%m-%d')\n",
        "            else:\n",
        "                date_str = str(latest_date)[:10]\n",
        "\n",
        "            latest_price = self.data.loc[latest_idx, 'Close']\n",
        "            if hasattr(latest_price, 'iloc'):\n",
        "                latest_price = float(latest_price.iloc[0])\n",
        "            else:\n",
        "                latest_price = float(latest_price)\n",
        "\n",
        "            latest_sentiment = self.get_news_sentiment(ticker, date_str)\n",
        "\n",
        "            # Predict using best model\n",
        "            predicted_price = self.best_model.predict([[latest_price, latest_sentiment]])\n",
        "\n",
        "            print(f\"📊 Current price: ${latest_price:.2f}\")\n",
        "            print(f\"🤖 Predicted price: ${predicted_price[0]:.2f}\")\n",
        "            change = predicted_price[0] - latest_price\n",
        "            change_pct = (change / latest_price) * 100\n",
        "            direction = \"📈\" if change > 0 else \"📉\" if change < 0 else \"➡️\"\n",
        "            print(f\"{direction} Expected change: ${change:.2f} ({change_pct:+.2f}%)\")\n",
        "\n",
        "            return float(predicted_price[0])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Prediction error: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "print(\"Welcome to StockSentry\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Get user inputs\n",
        "try:\n",
        "    NEWS_API_KEY = userdata.get('NEWS_API_KEY')\n",
        "    if not NEWS_API_KEY:\n",
        "        print(\"🔐 No API key found in secrets. Using demo mode.\")\n",
        "        NEWS_API_KEY = \"your_api_key_here\"\n",
        "except Exception as e:\n",
        "    print(\"🔐 Could not access Colab secrets. Using demo mode.\")\n",
        "    NEWS_API_KEY = \"your_api_key_here\"\n",
        "\n",
        "TICKER = input(\"Enter stock ticker (e.g., AAPL, GOOGL, TSLA): \").strip().upper()\n",
        "if not TICKER:\n",
        "    TICKER = \"AAPL\"\n",
        "    print(\"Using default ticker: AAPL\")\n",
        "\n",
        "print(\"\\nEnter date range for training data:\")\n",
        "START_DATE = input(\"Start date (YYYY-MM-DD format, e.g., 2023-01-01): \").strip()\n",
        "if not START_DATE:\n",
        "    START_DATE = \"2023-01-01\"\n",
        "    print(\"Using default start date: 2023-01-01\")\n",
        "\n",
        "END_DATE = input(\"End date (YYYY-MM-DD format, e.g., 2023-06-30): \").strip()\n",
        "if not END_DATE:\n",
        "    END_DATE = \"2023-06-30\"\n",
        "    print(\"Using default end date: 2023-06-30\")\n",
        "\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Initialize the enhanced StockSentry\n",
        "stock_sentry = StockSentryML(NEWS_API_KEY)\n",
        "\n",
        "# Train models and get the best one\n",
        "try:\n",
        "    best_model = stock_sentry.train_and_evaluate(TICKER, START_DATE, END_DATE)\n",
        "\n",
        "    # Get prediction\n",
        "    if best_model:\n",
        "        predicted_price = stock_sentry.predict_next_day(TICKER)\n",
        "\n",
        "        if predicted_price:\n",
        "            print(f\"\\n🎯 Final Prediction: ${predicted_price:.2f}\")\n",
        "        else:\n",
        "            print(\"\\n❌ Prediction failed\")\n",
        "    else:\n",
        "        print(\"\\n❌ Model training failed\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"✅ Analysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5s6X9ePDrn3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
